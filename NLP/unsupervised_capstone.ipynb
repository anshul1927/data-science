{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import glob\n",
    "import requests \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/movies_metadata.csv')\n",
    "# df.head()\n",
    "# df['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r = requests.get('https://medium.com/@garyvee/latest?format=json')\n",
    "# r.status_code\n",
    "# print(r.json)\n",
    "# print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tank_path = \"./data/medium_articles/\"\n",
    "df_medium = pd.DataFrame(columns=['text', 'author'])\n",
    "\n",
    "allTankFiles = glob.glob(tank_path + 'tank' + \"/*.txt\")\n",
    "allSpencerFiles = glob.glob(tank_path + 'spencer' + \"/*.txt\")\n",
    "allHorganFiles = glob.glob(tank_path + 'horgan' + \"/*.txt\")\n",
    "allHowardFiles = glob.glob(tank_path + 'howard' + \"/*.txt\")\n",
    "allKozyrkovFiles = glob.glob(tank_path + 'kozyrkov' + \"/*.txt\")\n",
    "allSeifFiles = glob.glob(tank_path + 'seif' + \"/*.txt\")\n",
    "allUlanoffFiles = glob.glob(tank_path + 'ulanoff' + \"/*.txt\")\n",
    "allVermeulenFiles = glob.glob(tank_path + 'vermeulen' + \"/*.txt\")\n",
    "allKoffFiles = glob.glob(tank_path + 'koff' + \"/*.txt\")\n",
    "allMarxFiles = glob.glob(tank_path + 'marx' + \"/*.txt\")\n",
    "\n",
    "# for file_ in allTankFiles:\n",
    "for idx, file_ in enumerate(allTankFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Tank'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allSpencerFiles:\n",
    "for idx, file_ in enumerate(allSpencerFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Spencer'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allHorganFiles:\n",
    "for idx, file_ in enumerate(allHorganFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Horgan'}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "# for file_ in allHowardFiles:\n",
    "for idx, file_ in enumerate(allHowardFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Howard'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allKozyrkovFiles:\n",
    "for idx, file_ in enumerate(allKozyrkovFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Kozyrkov'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allSeifFiles:\n",
    "for idx, file_ in enumerate(allSeifFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Seif'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allUlanoffFiles:\n",
    "for idx, file_ in enumerate(allUlanoffFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Ulanoff'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allVermeulenFiles:\n",
    "for idx, file_ in enumerate(allVermeulenFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Vermeulen'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allKoffFiles:\n",
    "for idx, file_ in enumerate(allKoffFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Koff'}, ignore_index=True)\n",
    "        \n",
    "# for file_ in allMarxFiles:\n",
    "for idx, file_ in enumerate(allMarxFiles):\n",
    "    with open(file_, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        df_medium = df_medium.append({'text': data, 'author': 'Marx'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medium.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The power of doing nothing at allOriginally pu...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The truth about toxic workers in the workplace...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the “Pursuit of Happiness” is leaving you ...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistakes that don’t (necessarily) kill startup...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t become an entrepreneur\\nOriginally publi...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Focus on productivity, not efficiencyDoing mor...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How unexpected tools can make your organizatio...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Curiosity doesn’t kill companies\\nBut poor lea...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop reading what makes Elon Musk and Bill Gat...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Why reading 100 books a year won’t make you su...</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RecodeAmazon will Prove the Retail Apocalypse ...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Google. Something went wrong on the internet.G...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Facebook CEO Mark Zuckerberg. GettyFacebook Ha...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is why ICOs are in disreputeEOS Huobi Col...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Why the World Needs a Basic Stipend and Univer...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TruU.S. Milks Canada with New NAFTA called USM...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GoWealth inequality still characterizes the ti...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Facebook is not sorry, it’s getting desperate....</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Getty imagesEnterprise Ethereum Alliance Open-...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Consumers visit a booth for Bytedance Technolo...</td>\n",
       "      <td>Spencer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   author\n",
       "0   The power of doing nothing at allOriginally pu...     Tank\n",
       "1   The truth about toxic workers in the workplace...     Tank\n",
       "2   Why the “Pursuit of Happiness” is leaving you ...     Tank\n",
       "3   Mistakes that don’t (necessarily) kill startup...     Tank\n",
       "4   Don’t become an entrepreneur\\nOriginally publi...     Tank\n",
       "5   Focus on productivity, not efficiencyDoing mor...     Tank\n",
       "6   How unexpected tools can make your organizatio...     Tank\n",
       "7   Curiosity doesn’t kill companies\\nBut poor lea...     Tank\n",
       "8   Stop reading what makes Elon Musk and Bill Gat...     Tank\n",
       "9   Why reading 100 books a year won’t make you su...     Tank\n",
       "10  RecodeAmazon will Prove the Retail Apocalypse ...  Spencer\n",
       "11  Google. Something went wrong on the internet.G...  Spencer\n",
       "12  Facebook CEO Mark Zuckerberg. GettyFacebook Ha...  Spencer\n",
       "13  This is why ICOs are in disreputeEOS Huobi Col...  Spencer\n",
       "14  Why the World Needs a Basic Stipend and Univer...  Spencer\n",
       "15  TruU.S. Milks Canada with New NAFTA called USM...  Spencer\n",
       "16  GoWealth inequality still characterizes the ti...  Spencer\n",
       "17  Facebook is not sorry, it’s getting desperate....  Spencer\n",
       "18  Getty imagesEnterprise Ethereum Alliance Open-...  Spencer\n",
       "19  Consumers visit a booth for Bytedance Technolo...  Spencer"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medium[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc = nlp(df_medium['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paragraph in my_doc:\n",
    "#     print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in my_doc.sents:\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
